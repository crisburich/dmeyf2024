{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/cburich_pymnts/buckets/b1/'\n",
    "dataset_path = base_path + 'datasets/'\n",
    "modelos_path = base_path + 'modelos/'\n",
    "db_path = base_path + 'db/'\n",
    "\n",
    "\n",
    "# base_path = 'C:/Users/Cristian Burich/Desktop/MA/segundo/eyf/'\n",
    "# dataset_path = base_path + 'datasets/'\n",
    "# modelos_path = base_path + 'modelos/'\n",
    "# db_path = base_path + 'db/'\n",
    "\n",
    "\n",
    "dataset_file = 'competencia_03_fe_U_k300.parquet'   # usamos la version sin U?\n",
    "\n",
    "ganancia_acierto = 273000\n",
    "costo_estimulo = 7000\n",
    "\n",
    "# agregue sus semillas\n",
    "semillas = [165229,165211,165203,165237,165247]\n",
    "\n",
    "# data = pd.read_parquet('/home/eanegrin/datasets/' + dataset_file)\n",
    "data = pd.read_parquet(dataset_path + dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['clase_ternaria_1', 'tmobile_app', 'cmobile_app_trx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clase_binaria1'] = np.nan\n",
    "data['clase_binaria2'] = np.nan\n",
    "\n",
    "# Update values while keeping NaN as NaN\n",
    "data['clase_binaria1'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, \n",
    "                                  np.where(data['clase_ternaria'].isna(), np.nan, 0))\n",
    "data['clase_binaria2'] = np.where(data['clase_ternaria'] == 'CONTINUA', 0, \n",
    "                                  np.where(data['clase_ternaria'].isna(), np.nan, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos pesos a las clases\n",
    "\n",
    "data['clase_peso'] = 1.0\n",
    "\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+2', 'clase_peso'] = 1.00002\n",
    "data.loc[data['clase_ternaria'] == 'BAJA+1', 'clase_peso'] = 1.00001\n",
    "\n",
    "data['clase_binaria'] = 0\n",
    "data['clase_binaria'] = np.where(data['clase_ternaria'] == 'BAJA+2', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_gan_eval(y_pred, data):\n",
    "    weight = data.get_weight()\n",
    "    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0) - np.where(weight < 1.00002, costo_estimulo, 0)\n",
    "    ganancia = ganancia[np.argsort(y_pred)[::-1]]\n",
    "    ganancia = np.cumsum(ganancia)\n",
    "\n",
    "    return 'gan_eval', np.max(ganancia) , True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meses_train = [201906, 201907, 201908, 201909, 201910, 201911, 201912,\n",
    "               202001, 202002, 202003, 202004, 202005,\n",
    "               202007, 202008, 202009, 202010, 202011, 202012,\n",
    "               202101, 202102, 202103, 202104, 202105, 202106, 202107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[data['foto_mes'].isin(meses_train)]\n",
    "\n",
    "\n",
    "X_train = train_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2', 'foto_mes'], axis=1)\n",
    "y_train_binaria1 = train_data['clase_binaria1']\n",
    "y_train_binaria2 = train_data['clase_binaria2']\n",
    "w_train = train_data['clase_peso']\n",
    "\n",
    "future_data = data[data['foto_mes'] == 202109]\n",
    "\n",
    "X_test = future_data.drop(['clase_ternaria', 'clase_peso', 'clase_binaria1','clase_binaria2', 'foto_mes'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos el study de optuna que optimizamos en el script anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-18 08:00:05,806] Using an existing study with name 'competencia2_lgbm_v08' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "storage_name = \"sqlite:///\" + db_path + \"optimization_lgbm.db\"\n",
    "study_name = \"competencia3_lgbm_k300\" # UPDATE\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    load_if_exists=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = study.trials_dataframe()\n",
    "resultados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 95,\n",
       " 'learning_rate': 0.014790793124814124,\n",
       " 'min_data_in_leaf': 1162,\n",
       " 'feature_fraction': 0.32039319093779284,\n",
       " 'bagging_fraction': 0.7236519946486292}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor cantidad de árboles para el mejor model 871\n",
      "Mejor cantidad de árboles para el mejor model 871\n",
      "Mejor cantidad de árboles para el mejor model 871\n",
      "Mejor cantidad de árboles para el mejor model 871\n",
      "Mejor cantidad de árboles para el mejor model 871\n"
     ]
    }
   ],
   "source": [
    "best_iter = study.best_trial.user_attrs[\"best_iter\"]\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'first_metric_only': True,\n",
    "    'boost_from_average': True,\n",
    "    'feature_pre_filter': False,\n",
    "    'max_bin': 31,\n",
    "    'num_leaves': study.best_trial.params['num_leaves'],\n",
    "    'learning_rate': study.best_trial.params['learning_rate'],\n",
    "    'min_data_in_leaf': study.best_trial.params['min_data_in_leaf'],\n",
    "    'feature_fraction': study.best_trial.params['feature_fraction'],\n",
    "    'bagging_fraction': study.best_trial.params['bagging_fraction'],\n",
    "    'seed': semillas[0],\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "\n",
    "corte = 10500  #Editar si hace falta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla inicial para reproducibilidad\n",
    "initial_seed = 165229\n",
    "random.seed(initial_seed)\n",
    "\n",
    "# Generar 30 semillas adicionales\n",
    "new_seeds = [random.randint(0, 200000) for _ in range(30)]\n",
    "\n",
    "\n",
    "# Placeholder for storing results from all seeds\n",
    "combined_results = []\n",
    "\n",
    "for seed in new_seeds:\n",
    "    print(f\"Running iteration with seed {seed}\")\n",
    "    \n",
    "    # Update seed in parameters\n",
    "    params['seed'] = seed\n",
    "    \n",
    "    # Train the model\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train, \n",
    "        label=y_train_binaria2, \n",
    "        weight=w_train\n",
    "    )\n",
    "    model = lgb.train(params, train_data, num_boost_round=best_iter)\n",
    "    \n",
    "    # Predict on test data\n",
    "    y_pred_lgm = model.predict(X_test)\n",
    "    \n",
    "    # Work on a copy of X_test to avoid modifying the original\n",
    "    X_test_copy = X_test.copy()\n",
    "    X_test_copy['pred_lgm'] = y_pred_lgm\n",
    "    \n",
    "    # Sort by probability and assign \"Predicted\" labels\n",
    "    idx = np.argsort(y_pred_lgm)[::-1]\n",
    "    X_test_copy.reset_index(drop=True, inplace=True)\n",
    "    X_test_copy = X_test_copy.iloc[idx]\n",
    "    \n",
    "    envios = np.zeros(len(X_test_copy), dtype=int)\n",
    "    envios[:corte] = 1\n",
    "    X_test_copy['Predicted'] = envios\n",
    "    \n",
    "    # Save output file for this seed (excluding pred_lgm)\n",
    "    file_name = f'k_306_results_seed_{seed}.csv'\n",
    "    output_path = base_path + 'exp/KA2000/' + file_name\n",
    "    output = X_test_copy[['numero_de_cliente', 'Predicted']]  # Exclude 'pred_lgm'\n",
    "    output.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Add the probabilities to the combined results for final aggregation\n",
    "    combined_results.append(X_test_copy[['numero_de_cliente', 'pred_lgm']].copy())\n",
    "\n",
    "# Combine results by averaging probabilities\n",
    "print(\"Combining results from all seeds...\")\n",
    "\n",
    "# Merge all seed predictions on `numero_de_cliente`\n",
    "final_results = combined_results[0].rename(columns={'pred_lgm': 'prob_0'})\n",
    "\n",
    "for i, result in enumerate(combined_results[1:], 1):\n",
    "    final_results = final_results.merge(\n",
    "        result.rename(columns={'pred_lgm': f'prob_{i}'}),\n",
    "        on='numero_de_cliente'\n",
    "    )\n",
    "\n",
    "# Average the probabilities across all seeds\n",
    "final_results['average_prob'] = final_results[[f'prob_{i}' for i in range(len(new_seeds))]].mean(axis=1)\n",
    "\n",
    "# Assign \"Predicted\" labels based on averaged probabilities\n",
    "final_results = final_results.sort_values(by='average_prob', ascending=False)\n",
    "final_results['Predicted'] = 0\n",
    "final_results.iloc[:corte, final_results.columns.get_loc('Predicted')] = 1\n",
    "\n",
    "# Save the final combined output\n",
    "final_output = final_results[['numero_de_cliente', 'Predicted']]\n",
    "final_file_name = 'final_combined_results_k306.csv'\n",
    "final_output_path = base_path + 'exp/KA2000/' + final_file_name\n",
    "final_output.to_csv(final_output_path, index=False)\n",
    "\n",
    "print(f\"Final combined results saved to {final_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
